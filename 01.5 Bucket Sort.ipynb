{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01.5: Bucket Sort\n",
    "### Opdracht 1.5: Bucket Sort\n",
    "## 01.5.1 Implementing Bucket Sort for integers\n",
    "The first part of this assignment is implementing bucket sort. This implementation takes the following steps:\n",
    "\n",
    "1. Map data to strings\n",
    "2. Check if exit condition has been calculated:\n",
    "    1. If not, set it maximum to the length of the longest string\n",
    "3. Generate the buckets' columns. In the given psuedo-code, one would also generate the rows. This style would add extra overhead to the algorith, and has not been implemented.\n",
    "4. Distribution pass\n",
    "    1. Loop through the strings generated at **1.** and the original data simultaneously. \n",
    "    2. Check if index_offset is greater or equal to the length of the string\n",
    "        1. If yes, append the integer to bucket 0\n",
    "        2. Else, continue\n",
    "    3. Get the character at the wanted index (In the first iteration, the rightmost position)\n",
    "    4. This character equals the index of this item's bucket\n",
    "    5. Append the integer to the bucket with the columnindex of character\n",
    "5. Gathering pass\n",
    "    1. For each bucket in buckets, concatenate to a new list\n",
    "6. Increase index offset by 1\n",
    "7. Check if index offset is greater or equal to the maximum (exit condition)\n",
    "    1. If yes, return the array generated in **5.**\n",
    "    2. If no, call bucket sort again with the array generated in **5.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucket_sort_int(data, index_offset=0, maximum=None):\n",
    "    # Number of items in data\n",
    "    n = len(data)\n",
    "    # Map data to strings\n",
    "    str_data = list(map(str, data))\n",
    "    \n",
    "    # Check if exit condition has been established (maximum)\n",
    "    if not maximum:\n",
    "        # If not, generate maximum\n",
    "        maximum = len(max(str_data, key=len))\n",
    "   \n",
    "    \n",
    "    # Generate buckets\n",
    "    buckets = [[] for __ in range(10)]\n",
    "    \n",
    "    # Distribution pass\n",
    "    for integer, string in zip(data, str_data):\n",
    "        if index_offset >= len(string):\n",
    "            buckets[0].append(integer)\n",
    "        else:\n",
    "            character = string[-1 - index_offset]\n",
    "            bucket_number = int(character)\n",
    "            buckets[bucket_number].append(integer)\n",
    "    \n",
    "    # Gathering pass\n",
    "    new_data = []\n",
    "    for bucket in buckets:\n",
    "        new_data += bucket\n",
    "    \n",
    "    # Set new index_offset\n",
    "    index_offset += 1\n",
    "    # Check if exit condition has been reached (index_offset >= maximum)\n",
    "    if index_offset >= maximum:\n",
    "        # If exit condition has been reached, return new_data\n",
    "        return new_data\n",
    "    else:\n",
    "        # Else, recursively call bucket_sort again\n",
    "        return bucket_sort_int(new_data, index_offset=index_offset, maximum=maximum)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 15, 31, 50]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_sort_int([50,1, 15,1,2,31])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this implementation works on smaller lists, how does it perform on big lists?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_lists():\n",
    "    \"\"\"Taken from 01.1\"\"\"\n",
    "    thirtyK  = np.arange(0, 30_000)\n",
    "    tenK     = np.arange(0, 10_000)\n",
    "    oneK     = np.arange(0, 1_000)\n",
    "    \n",
    "    np.random.shuffle(thirtyK)\n",
    "    np.random.shuffle(tenK)\n",
    "    np.random.shuffle(oneK)\n",
    "    return thirtyK, tenK, oneK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thirtyK, _, _  = give_lists()\n",
    "sorted_thirtyK = bucket_sort_int(thirtyK)\n",
    "sorted_thirtyK == sorted(thirtyK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If Python's ```Sorted``` function is to be believed, this buck sort implementation has properly sorted a randomly-filled list with 30 thousand items!\n",
    "\n",
    "## 01.5.2 Sorting, speed!\n",
    "Next up is analysing bucket sort. How fast is it, and what type of time complexity does it have?  \n",
    "\n",
    "Using the time testing functions from 01.1, it can be timed:\n",
    "\n",
    "For a completely random set of lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_sort_func(func):\n",
    "    \"\"\"Taken from 01.1\"\"\"\n",
    "    # TODO redo with cProfile    \n",
    "    thirtyK, tenK, oneK = give_lists()\n",
    "    oneK_time    = %timeit -r 1 -n 1 -o -q func(oneK)\n",
    "    tenK_time    = %timeit -r 1 -n 1 -o -q func(tenK)\n",
    "    thirtyK_time = %timeit -r 1 -n 1 -o -q func(thirtyK)\n",
    "    \n",
    "    \n",
    "    return {\"1.000\" : oneK_time, \"10.000\" : tenK_time, \"30.000\" : thirtyK_time}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1.000': <TimeitResult : 2.63 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)>,\n",
       " '10.000': <TimeitResult : 38.1 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)>,\n",
       " '30.000': <TimeitResult : 128 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_sort_func(bucket_sort_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a pre-sorted list of 30 thousand items:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_presorted_func(func):\n",
    "    thirtyK = np.arange(0, 30_000)\n",
    "    %timeit -r 2 -n 2 func(thirtyK)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126 ms ± 3.58 ms per loop (mean ± std. dev. of 2 runs, 2 loops each)\n"
     ]
    }
   ],
   "source": [
    "partial_presorted_func(bucket_sort_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a reversed list of 30 thousand items:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_reversed_func(func):\n",
    "    thirtyK = np.arange(0, 30_000)[::-1]\n",
    "    %timeit -r 1 -n 1 func(thirtyK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "partial_reversed_func(bucket_sort_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is remarkably faster than the fastest sorting algorithm in 01.1, merge sort. It took merge sort approximately 1.17 seconds to sort 30.000 items. Bucket sort does this in 128 milliseconds. Merge sort is about 9 times faster in this scenario!\n",
    "\n",
    "The next question to answer, what type of time complexity can be used to describe bucket sort. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
